<html>
    <meta name="viewport" content="width=600","initial-scale=1"/>
  <body>
    <div class="contentarea">
      <div class="camera">
        <video id="video">Video stream not available.</video>
        <button id="startbutton">Take photo</button>
      </div>
      <canvas id="canvas"> </canvas>
      <div class="output">
        <img id="photo" alt="The screen capture will appear in this box." />
      </div>
      <p>
        Visit our article
        <a
          href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Capture_and_Streams_API/Taking_still_photos">
          Taking still photos with WebRTC</a
        >
        to learn more about the technologies used here.
      </p>
    </div>

    <style>
      #video {
        border: 1px solid black;
        box-shadow: 2px 2px 3px black;
        width: 100vw;
        height: 80vh;
      }
      
      #photo {
        border: 1px solid black;
        box-shadow: 2px 2px 3px black;
        width: 100vw;
      }
      
      #canvas {
        display: none;
      }
      
      .camera {
      }
      
      .output {
        display: inline-block;
        vertical-align: top;
      }
      
      #startbutton {
        display: block;
        position: relative;
        margin-left: auto;
        margin-right: auto;
        bottom: 32px;
        padding: 10px;
        background-color: rgb(0 150 0 / 50%);
        border: 1px solid rgb(255 255 255 / 70%);
        box-shadow: 0px 0px 1px 2px rgb(0 0 0 / 20%);
        font-size: 14px;
        font-family: "Lucida Grande", "Arial", sans-serif;
        color: rgb(255 255 255 / 100%);
      }
      
      .contentarea {
        font-size: 16px;
        font-family: "Lucida Grande", "Arial", sans-serif;
        width: 760px;
      }
    </style>

    <script>
      (() => {
        // The width and height of the captured photo. We will set the
        // width to the value defined here, but the height will be
        // calculated based on the aspect ratio of the input stream.
      
        const width = window.innerWidth; // We will scale the photo width to this
        let height = window.innerHeight - 200; // This will be computed based on the input stream
      
        // |streaming| indicates whether or not we're currently streaming
        // video from the camera. Obviously, we start at false.
      
        let streaming = false;
      
        // The various HTML elements we need to configure or control. These
        // will be set by the startup() function.
      
        let video = null;
        let canvas = null;
        let photo = null;
        let startbutton = null;
      
        function startup() {
          video = document.getElementById("video");
          canvas = document.getElementById("canvas");
          photo = document.getElementById("photo");
          startbutton = document.getElementById("startbutton");
      
          navigator.mediaDevices
            .getUserMedia({ 
                video: {
                  width: {
        				ideal: 3240
        			},
        			height: {
        				ideal: 2160
        			},
        			facingMode: { exact: 'environment' },
        			// torch: true,
        			focusMode: 'continuous'
                }, 
                audio: false 
            })
            .then((stream) => {
              video.srcObject = stream;
              video.play();
            })
            .catch((err) => {
              console.error(`An error occurred: ${err}`);
            });
      
          video.addEventListener(
            "canplay",
            (ev) => {
              if (!streaming) {
                height = video.videoHeight;
                width = video.videoWidth;
                    // (video.videoWidth / width);
      
                // Firefox currently has a bug where the height can't be read from
                // the video, so we will make assumptions if this happens.
      
                if (isNaN(height)) {
                  height = width / (4 / 3);
                }
      
                video.setAttribute("width", width);
                video.setAttribute("height", height);
                canvas.setAttribute("width", width);
                canvas.setAttribute("height", height);
                streaming = true;
              }
            },
            false,
          );
      
          startbutton.addEventListener(
            "click",
            (ev) => {
              takepicture();
              ev.preventDefault();
            },
            false,
          );
      
          clearphoto();
        }
      
        // Fill the photo with an indication that none has been
        // captured.
      
        function clearphoto() {
          const context = canvas.getContext("2d");
          context.fillStyle = "#AAA";
          context.fillRect(0, 0, canvas.width, canvas.height);
      
          const data = canvas.toDataURL("image/png");
          photo.setAttribute("src", data);
        }
      
        // Capture a photo by fetching the current contents of the video
        // and drawing it into a canvas, then converting that to a PNG
        // format data URL. By drawing it on an offscreen canvas and then
        // drawing that to the screen, we can change its size and/or apply
        // other changes before drawing it.
      
        function takepicture() {
          const context = canvas.getContext("2d");
          if (width && height) {
            canvas.width = width;
            canvas.height = height;
            context.drawImage(video, 0, 0, width, height);
      
            const data = canvas.toDataURL("image/png");
            photo.setAttribute("src", data);
          } else {
            clearphoto();
          }
        }
      
        // Set up our event listener to run the startup process
        // once loading is complete.
        window.addEventListener("load", startup, false);
      })();
    </script>

  </body>
</html>
